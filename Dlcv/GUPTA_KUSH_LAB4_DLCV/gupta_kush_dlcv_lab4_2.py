# -*- coding: utf-8 -*-
"""GUPTA_KUSH_DLCV_lab4_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tdtfTnBRp9UCddEkpjOfnA76Rz6_fmyD
"""

import torch
from torch import nn,optim,softmax,max
from torch.utils.data import DataLoader
from torchvision.utils import make_grid
from torchvision import datasets,models
from torchvision import transforms
import matplotlib.pyplot as plt
import numpy as np

# Get cpu or gpu device for training.
device = "cuda:0" if torch.cuda.is_available() else "cpu"
print(f"Using {device} device")

transform_train = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

training_data = datasets.CIFAR10(root="./data", download=True,
                                      train=True, 
                                      transform=transform_train)

test_data = datasets.CIFAR10(root="./data", download=True,
                                  train=False,
                                  transform=transform_test)

batch_size = 32

train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True, num_workers=2)
test_dataloader = DataLoader(test_data, batch_size=batch_size,shuffle = False, num_workers=2)

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

#Function to show images
def show_img(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()

# get some random training images
dataiter = iter(train_dataloader)
images, labels = next(dataiter)
# show images
show_img(make_grid(images))
# print labels
print(' '.join(f'{classes[labels[j]]:5s}'+'\n' for j in range(batch_size)))

class Neural_net(nn.Module):
  def __init__(self):
    super(Neural_net,self).__init__()

    # creating the 2D convolution layers
    self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)
    self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)

    #creating drop-out layers
    self.dc1= nn.Dropout(0.25)
    self.dc2= nn.Dropout(0.5)

    #Creating Max-Pooling 
    self.mp1= nn.MaxPool2d(2,stride=2)

    #Fully Connected layer mapping the output of the convolutional layers to 128
    self.fc1= nn.Linear(32* 16* 16,256)
    
    self.fc2 = nn.Linear(256, 128)
    #Fully connected layers for 10 classes
    self.fc3 = nn.Linear(128, 10)

  def forward(self,X):
    relu = torch.nn.ReLU()

    #applying convlution and ReLU
    X = relu(self.conv1(X))
    X = relu(self.conv2(X))
        
    #print('before max pooling:',X.shape)
    #applying Max pooling
    
    X=self.mp1(X)
    
    #applying drop out
    X=self.dc1(X)

    #print('Afer max pooling:', X.shape)

    #Flattening the inputs
    X = X.reshape(-1,32* 16* 16)    
    X = relu(self.fc1(X))

    #applying drop out
    #X = self.dc2(X)

    X = relu(self.fc2(X))
  
    output = self.fc3(X)
    
    return output

model= Neural_net()
model.to(device)
print(model)

loss_func = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(),lr=0.01)

def train_for_epoch(dataloader):

    # putting model in train mode
    model.train()

    # keep track of the training losses during the epoch
    train_losses = []

    for batch, targets in dataloader:
        batch = batch.to(device)
        targets = targets.to(device)

        # clear previous gradient computation
        optimizer.zero_grad()

        # forward propagation
        predictions = model(batch)
        
        # calculate the loss
        loss = loss_func(predictions, targets)

        # backpropagate to compute gradients
        loss.backward()

        # update model weights
        optimizer.step()

        # update average loss
        train_losses.append(loss.item())

    # calculate average training loss
    train_loss = np.mean(train_losses)

    return train_loss

def train(first_epoch, num_epochs,train_dataloader):
    
    train_losses = []

    for epoch in range(first_epoch, first_epoch + num_epochs):

        # training phase
        train_loss = train_for_epoch(train_dataloader)      

        print(f'epoch: [{epoch:02d}] train loss: {train_loss:04f}')
        
        train_losses.append(train_loss)
    
    return train_losses

def plot_loss(train_loss):
  epochs = range(1, len(train_loss) + 1)
  plt.figure(figsize=(10,6))
  plt.plot(epochs, train_loss, '-o', label='Training loss')
  plt.legend()
  plt.title('Learning curve')
  plt.xlabel('Epoch')
  plt.ylabel('Loss')
  plt.xticks(epochs)
  plt.show()

# Train the Neural Network
train_loss=train(1,20,train_dataloader)

#Plot the loss of the Neural Network
plot_loss(train_loss)

def check_accuracy(dataloader):
  # putting model in evaluation mode
    model.eval()
    
    y_pred=[]

    with torch.no_grad():

      #go over each batch to determine model accuracy.

      for batch,_ in dataloader:
        batch = batch.to(device)
        # Predict probabilty of each class
        predictions = model(batch)

        #applying softmax on predictions
        predictions = softmax(predictions,dim=1)

        # convert to numpy
        predictions = predictions.cpu().numpy()

        # save
        y_pred.append(predictions)
    
    # stack predictions into a (num_samples, 10) array
    y_pred = np.vstack(y_pred)
    return y_pred

# compute predictions on the test set
y_pred = check_accuracy(test_dataloader)
# find the argmax of each of the predictions
y_pred = y_pred.argmax(axis=1)
# get the true labels and convert to numpy
y_true = np.array(test_data.targets)
# Calculate accuracy as the average number of times y_true == y_pred
accuracy = np.mean(np.equal(y_pred,y_true))
print(accuracy)

error_indicator = y_pred != y_true
error_examples = test_data.data[error_indicator, :, :]
sample = error_examples[:10]
fig, axes = plt.subplots(nrows=1, ncols=10, figsize=(20,20))
plt.grid(False)
plt.xticks([])
plt.yticks([])
for i in range(sample.shape[0]):
  axes[i].set_title('True label:'+classes[y_true[error_indicator][i]]+'\n''Predict_label:'+ classes[y_pred[error_indicator][i]]+'\n')
  axes[i].imshow(sample[i,:,:,:])
  
plt.show()

"""#Using the Best Model from Lab *3.3* on CIFAR-10 *Dataset*"""

# Defining the best model in the lab 3.3
class Neural_net2(nn.Module):
  def __init__(self):
    super(Neural_net2,self).__init__()

    #Fully Connected layer
    self.fc1= nn.Linear(32* 32* 3,128)
    
    #Fully connected layers for 10 classes
    self.fc2 = nn.Linear(128, 10)

  def forward(self,X):
    relu = torch.nn.ReLU()

    #Flattening the inputs
    X = X.reshape(-1,32* 32* 3)    
    X = relu(self.fc1(X))

    output = self.fc2(X)
    
    return output

#for comparison with the best neural network from lab 3.3 uncomment the below code and comment the above model defn.
model= Neural_net2()
model.to(device)
print(model)

loss_func = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(),lr=0.01)

def train_for_epoch():

    # putting model in train mode
    model.train()

    # keep track of the training losses during the epoch
    train_losses = []

    for batch, targets in train_dataloader:
        batch = batch.to(device)
        targets = targets.to(device)

        # clear previous gradient computation
        optimizer.zero_grad()

        # forward propagation
        predictions = model(batch)
        
        # calculate the loss
        loss = loss_func(predictions, targets)

        # backpropagate to compute gradients
        loss.backward()

        # update model weights
        optimizer.step()

        # update average loss
        train_losses.append(loss.item())

    # calculate average training loss
    train_loss = np.mean(train_losses)

    return train_loss

def train(first_epoch, num_epochs):
    
    train_losses = []

    for epoch in range(first_epoch, first_epoch + num_epochs):

        # training phase
        train_loss = train_for_epoch()      

        print(f'epoch: [{epoch:02d}] train loss: {train_loss:04f}')
        
        train_losses.append(train_loss)
    
    return train_losses

train_loss=train(1,20)

epochs = range(1, len(train_loss) + 1)

plt.figure(figsize=(10,6))
plt.plot(epochs, train_loss, '-o', label='Training loss')
plt.legend()
plt.title('Learning curves')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.xticks(epochs)
plt.show()

def check_accuracy(dataloader):
  # putting model in evaluation mode
    model.eval()
    
    y_pred=[]

    with torch.no_grad():

      #go over each batch to determine model accuracy.

      for batch,_ in dataloader:
        batch = batch.to(device)
        # Predict probabilty of each class
        predictions = model(batch)

        #applying softmax on predictions
        predictions = softmax(predictions,dim=1)

        # convert to numpy
        predictions = predictions.cpu().numpy()

        # save
        y_pred.append(predictions)
    
    # stack predictions into a (num_samples, 10) array
    y_pred = np.vstack(y_pred)
    return y_pred

# compute predictions on the test set
y_pred = check_accuracy(test_dataloader)

# find the argmax of each of the predictions
y_pred = y_pred.argmax(axis=1)

# get the true labels and convert to numpy
y_true = np.array(test_data.targets)

# Calculate accuracy as the average number of times y_true == y_pred
accuracy = np.mean(np.equal(y_pred,y_true))
print(accuracy)

"""# 3 Data Augumentation"""

# Data Augumention
aug_transform_train = transforms.Compose([
    transforms.RandomAdjustSharpness(5), # Randomly adjusting the sharpness
    transforms.ColorJitter(brightness=1.5, contrast=0.75, saturation=1.25), # Randomly changing the HSV
    transforms.RandomHorizontalFlip(0.5), #Horizontal flipling the data
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

training_data2 = datasets.CIFAR10(root="./data", download=True,
                                      train=True, 
                                      transform=aug_transform_train)

train_dataloader2 = DataLoader(training_data2, batch_size=batch_size, shuffle=True, num_workers=2)

train_loss=train(1,40,train_dataloader2)

plot_loss(train_loss)

# compute predictions on the test set
y_pred2 = check_accuracy(test_dataloader)
# find the argmax of each of the predictions
y_pred2 = y_pred2.argmax(axis=1)
# get the true labels and convert to numpy
y_true = np.array(test_data.targets)
# Calculate accuracy as the average number of times y_true == y_pred
accuracy = np.mean(np.equal(y_pred2,y_true))
print(accuracy)

error_indicator = y_pred2 != y_true
error_examples = test_data.data[error_indicator, :, :]
sample = error_examples[:10]
fig, axes = plt.subplots(nrows=1, ncols=10, figsize=(20,20))
plt.grid(False)
plt.xticks([])
plt.yticks([])
for i in range(sample.shape[0]):
  axes[i].set_title('True label:'+classes[y_true[error_indicator][i]]+'\n''Predict_label:'+ classes[y_pred2[error_indicator][i]]+'\n')
  axes[i].imshow(sample[i,:,:,:])
  
plt.show()

"""# Transfer learning / fine-tuning on CIFAR10 dataset"""

# Data Augumention
aug_transform_train_tl = transforms.Compose([
    transforms.RandomAdjustSharpness(5), # Randomly adjusting the sharpness
    transforms.ColorJitter(brightness=1.5, contrast=0.75, saturation=1.25), # Randomly changing the HSV
    transforms.RandomHorizontalFlip(0.5), #Horizontal flipling the data
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
aug_transform_test_tl = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

training_data3 = datasets.CIFAR10(root="./data", download=True,
                                      train=True, 
                                      transform=aug_transform_train_tl)

test_data3 = datasets.CIFAR10(root="./data", download=True,
                                      train=False, 
                                      transform=aug_transform_test_tl)

train_dataloader3 = DataLoader(training_data3, batch_size=batch_size, shuffle=True, num_workers=2)
test_dataloader3 = DataLoader(test_data3, batch_size=batch_size, num_workers=2)

# Using the resnet 50 pretrained on imagenet
model = models.resnet50(pretrained='imagenet')
input_features = model.fc.in_features
model.fc = nn.Linear(input_features,10)

model.to(device)
print(model)

loss_func = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(),lr=0.01)
train_loss=train(1,10,train_dataloader3)

plot_loss(train_loss)

# compute predictions on the test set
y_pred3 = check_accuracy(test_dataloader)
# find the argmax of each of the predictions
y_pred3 = y_pred3.argmax(axis=1)
# get the true labels and convert to numpy
y_true = np.array(test_data.targets)
# Calculate accuracy as the average number of times y_true == y_pred
accuracy = np.mean(np.equal(y_pred3,y_true))
print(accuracy)